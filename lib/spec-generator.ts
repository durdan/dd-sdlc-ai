import { createOpenAI } from '@ai-sdk/openai';
import { streamText, generateText } from 'ai';
import {
  RepoAnalysisData,
  GeneratedSpec,
  SpecMetadata,
  SpecSections,
} from '@/types/analyzer';
import { formatDirectoryTree, calculateLanguagePercentages } from './github-analyzer';

const openai = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY || '',
});

/**
 * Generate a comprehensive specification from repository analysis data
 */
export async function generateSpec(analysisData: RepoAnalysisData): Promise<GeneratedSpec> {
  const prompt = buildAnalysisPrompt(analysisData);

  const { text: markdown } = await generateText({
    model: openai('gpt-4o'),
    maxTokens: 8000,
    system: 'You are an expert software architect analyzing GitHub repositories to generate comprehensive project specifications. Your output should be professional, detailed, and immediately useful for developers.',
    prompt,
  });

  if (!markdown) {
    throw new Error('No content in response');
  }

  // Parse sections from markdown (basic parsing)
  const sections = parseSpecSections(markdown, analysisData);

  // Build metadata
  const metadata: SpecMetadata = {
    generatedAt: new Date().toISOString(),
    repoUrl: analysisData.info.html_url,
    repoOwner: analysisData.info.owner.login,
    repoName: analysisData.info.name,
    analysisVersion: '1.0',
  };

  return {
    markdown,
    sections,
    metadata,
  };
}

/**
 * Build the analysis prompt
 */
function buildAnalysisPrompt(data: RepoAnalysisData): string {
  const languageBreakdown = calculateLanguagePercentages(data.languages);
  const directoryTreeStr = formatDirectoryTree(data.directoryTree);

  // Format key files content
  const keyFilesContent = data.keyFiles
    .map((f) => `### ${f.name}\n\`\`\`\n${f.content.substring(0, 3000)}\n\`\`\``)
    .join('\n\n');

  return `Analyze this GitHub repository and generate a comprehensive project specification.

## Repository Information
- **Name**: ${data.info.name}
- **Full Name**: ${data.info.full_name}
- **Description**: ${data.info.description || 'No description provided'}
- **Primary Language**: ${data.info.language || 'Unknown'}
- **Topics**: ${data.info.topics?.join(', ') || 'None'}
- **Stars**: ${data.info.stargazers_count}
- **Forks**: ${data.info.forks_count}
- **Open Issues**: ${data.info.open_issues_count}
- **License**: ${data.info.license?.name || 'Not specified'}
- **Last Updated**: ${data.info.pushed_at}
- **Archived**: ${data.info.archived ? 'Yes' : 'No'}

## Language Breakdown
${languageBreakdown.map((l) => `- ${l.language}: ${l.percentage}%`).join('\n')}

## Detected Technologies
- **Frameworks**: ${data.detectedFrameworks.join(', ') || 'None detected'}
- **Databases**: ${data.detectedDatabases.join(', ') || 'None detected'}
- **Infrastructure**: ${data.detectedInfrastructure.join(', ') || 'None detected'}

## README Content
${data.readme ? data.readme.substring(0, 5000) : 'No README found'}

## Directory Structure
\`\`\`
${directoryTreeStr}
\`\`\`

## Key Configuration Files
${keyFilesContent || 'No key files found'}

## Top Contributors
${data.contributors.map((c) => `- ${c.login} (${c.contributions} contributions)`).join('\n') || 'No contributors data'}

## Latest Release
${data.latestRelease ? `${data.latestRelease.name || data.latestRelease.tag_name} (${data.latestRelease.published_at})` : 'No releases'}

---

## Your Task

Generate a comprehensive project specification in Markdown format. Follow this EXACT structure:

# ${data.info.name} - Project Specification

> Auto-generated by SDLC.dev | Generated on ${new Date().toISOString().split('T')[0]}
> Source: ${data.info.html_url}

## 1. Project Overview
- **Purpose**: What this project does (2-3 sentences)
- **Type**: Library / CLI Tool / Web App / API / Framework / Mobile App / etc.
- **Status**: Active / Maintained / Archived
- **License**: ${data.info.license?.name || 'Not specified'}

## 2. Tech Stack
| Layer | Technology | Version (if known) |
|-------|------------|-------------------|
| Language | ... | ... |
| Framework | ... | ... |
| Database | ... | ... |
| ORM | ... | ... |
| Styling | ... | ... |
| Testing | ... | ... |
| Infrastructure | ... | ... |

## 3. Architecture Overview

### System Diagram
\`\`\`mermaid
graph TB
    ... (create a diagram specific to this project's architecture)
\`\`\`

IMPORTANT Mermaid Syntax Rules:
- Node IDs MUST NOT contain spaces. Use underscores or camelCase (e.g., OpenAI_API, not OpenAI API)
- For display labels with spaces, use bracket notation: NodeID["Display Label With Spaces"]
- Example: API["OpenAI API"] or Redis_Cache["Redis Cache"]
- Keep node IDs short and alphanumeric

### Key Components
- **Component 1**: Description
- **Component 2**: Description

### Directory Structure
Provide a simplified, annotated directory structure.

## 4. Core Features
- Feature 1
- Feature 2
- Feature 3

## 5. API Reference (if applicable)
| Endpoint | Method | Description |
|----------|--------|-------------|
| /api/... | GET | ... |

## 6. Data Models (if detected)
Document database schemas or data structures if found.

## 7. Getting Started
### Prerequisites
### Installation
### Configuration
### Running the Project

## 8. Documentation Gaps
- [ ] Missing item 1
- [ ] Missing item 2

## 9. Project Metrics
- Stars: ${data.info.stargazers_count}
- Forks: ${data.info.forks_count}
- Open Issues: ${data.info.open_issues_count}
- Last Updated: ${data.info.pushed_at}
- Contributors: ${data.contributors.length}+

---
Generated by [SDLC.dev](https://sdlc.dev) | [Analyze your repo](https://sdlc.dev/analyze)

## Guidelines:
1. Be SPECIFIC - reference actual file names and components
2. The Mermaid diagram MUST reflect the actual architecture
3. If uncertain, say "Could not be determined from repository analysis"
4. Focus on what makes THIS project unique
5. Keep it actionable for developers
6. Do not invent features not evident from the data`;
}

/**
 * Parse spec sections from markdown (basic parsing)
 */
function parseSpecSections(markdown: string, analysisData: RepoAnalysisData): SpecSections {
  const info = analysisData.info;

  return {
    overview: {
      purpose: info.description || 'No description available',
      type: detectProjectType(analysisData),
      status: info.archived ? 'Archived' : info.pushed_at ? 'Active' : 'Unknown',
      license: info.license?.name || null,
    },
    techStack: [
      { layer: 'Language', technology: info.language || 'Unknown' },
      ...analysisData.detectedFrameworks.map((f) => ({ layer: 'Framework', technology: f })),
      ...analysisData.detectedDatabases.map((d) => ({ layer: 'Database', technology: d })),
      ...analysisData.detectedInfrastructure.map((i) => ({ layer: 'Infrastructure', technology: i })),
    ],
    architecture: {
      mermaidDiagram: extractMermaidDiagram(markdown),
      components: [],
      directoryStructure: formatDirectoryTree(analysisData.directoryTree),
    },
    features: extractFeatures(markdown),
    gettingStarted: {
      prerequisites: [],
      installation: '',
      configuration: '',
    },
    documentationGaps: extractDocumentationGaps(markdown),
    metrics: {
      stars: info.stargazers_count,
      forks: info.forks_count,
      lastUpdated: info.pushed_at,
      contributorsCount: analysisData.contributors.length,
      openIssues: info.open_issues_count,
    },
  };
}

/**
 * Detect project type from analysis data
 */
function detectProjectType(data: RepoAnalysisData): string {
  const frameworks = data.detectedFrameworks;
  const hasWebFramework = frameworks.some((f) =>
    ['Next.js', 'React', 'Vue.js', 'Angular', 'Nuxt', 'Svelte'].includes(f)
  );
  const hasApiFramework = frameworks.some((f) =>
    ['Express', 'Fastify', 'NestJS', 'Django', 'Flask', 'FastAPI', 'Gin', 'Fiber'].includes(f)
  );

  const hasCli = data.keyFiles.some((f) => {
    if (f.name === 'package.json') {
      try {
        const pkg = JSON.parse(f.content);
        return pkg.bin !== undefined;
      } catch {
        return false;
      }
    }
    return false;
  });

  if (hasCli) return 'CLI Tool';
  if (hasWebFramework && hasApiFramework) return 'Full-Stack Web App';
  if (hasWebFramework) return 'Web App';
  if (hasApiFramework) return 'API / Backend Service';

  const language = data.info.language?.toLowerCase();
  if (language === 'rust' || language === 'go') {
    return data.info.description?.toLowerCase().includes('cli') ? 'CLI Tool' : 'Library / Tool';
  }

  return 'Library / Package';
}

/**
 * Extract Mermaid diagram from markdown
 */
function extractMermaidDiagram(markdown: string): string {
  const match = markdown.match(/```mermaid\n([\s\S]*?)```/);
  return match ? match[1].trim() : '';
}

/**
 * Extract features from markdown
 */
function extractFeatures(markdown: string): string[] {
  const features: string[] = [];
  const featuresSection = markdown.match(/## 4\. Core Features\n([\s\S]*?)(?=\n## |$)/);

  if (featuresSection) {
    const lines = featuresSection[1].split('\n');
    for (const line of lines) {
      const match = line.match(/^[-*]\s+(.+)/);
      if (match) {
        features.push(match[1].trim());
      }
    }
  }

  return features;
}

/**
 * Extract documentation gaps from markdown
 */
function extractDocumentationGaps(markdown: string): string[] {
  const gaps: string[] = [];
  const gapsSection = markdown.match(/## 8\. Documentation Gaps\n([\s\S]*?)(?=\n## |$)/);

  if (gapsSection) {
    const lines = gapsSection[1].split('\n');
    for (const line of lines) {
      const match = line.match(/^[-*\[\]x\s]+(.+)/);
      if (match) {
        gaps.push(match[1].trim());
      }
    }
  }

  return gaps;
}

/**
 * Generate a short share ID
 */
export function generateShareId(): string {
  const chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789';
  let result = '';
  for (let i = 0; i < 8; i++) {
    result += chars.charAt(Math.floor(Math.random() * chars.length));
  }
  return result;
}

/**
 * Stream spec generation (for real-time updates)
 */
export async function* streamSpec(
  analysisData: RepoAnalysisData
): AsyncGenerator<{ type: 'progress' | 'content' | 'done'; data: string }> {
  yield { type: 'progress', data: 'Starting specification generation...' };

  const prompt = buildAnalysisPrompt(analysisData);

  const result = await streamText({
    model: openai('gpt-4o'),
    maxTokens: 8000,
    system: 'You are an expert software architect analyzing GitHub repositories to generate comprehensive project specifications. Your output should be professional, detailed, and immediately useful for developers.',
    prompt,
  });

  for await (const textPart of result.textStream) {
    if (textPart) {
      yield { type: 'content', data: textPart };
    }
  }

  yield { type: 'done', data: 'Specification generated successfully' };
}
